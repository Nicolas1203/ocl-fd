
learner         :       ER
optim           :       SGD
learning_rate   :       0.01
momentum        :       0.9
weight_decay    :       0.0001
dataset         :       tiny
n_tasks         :       100
mem_size        :       2000
mem_batch_size  :       64
batch_size      :       10
nf              :       64
training_type   :       inc
