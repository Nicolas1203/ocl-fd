
learner         :       FD
optim           :       Adam
learning_rate   :       0.0005
momentum        :       0
weight_decay    :       0
var             :       2
eval_mem        :       True
dataset         :       tiny
n_tasks         :       100
mem_size        :       2000
mem_batch_size  :       64
batch_size      :       10
proj_dim        :       512
n_augs          :       5
nf              :       64
training_type   :       inc
fd_loss         :       agd
