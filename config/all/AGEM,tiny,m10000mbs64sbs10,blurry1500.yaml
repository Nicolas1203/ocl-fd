
learner         :       AGEM
optim           :       SGD
learning_rate   :       0.1
momentum        :       0
weight_decay    :       0.0001
dataset         :       tiny
n_tasks         :       100
mem_size        :       10000
mem_batch_size  :       64
batch_size      :       10
nf              :       64
training_type   :       blurry
blurry_scale    :       1500
